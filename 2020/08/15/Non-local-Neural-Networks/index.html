<!DOCTYPE html>
<html lang="zh-CN">

  <head>
  <meta charset="utf-8">
  <meta name="author" content="zchengsite, 1451426471@qq.com" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  
  <title>Non-local Neural Networks | Sditch</title>

  
    <link rel="apple-touch-icon" href="/images/favicon.ico">
    <link rel="icon" href="/images/favicon.ico">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  
<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/iconfont/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">


  <!-- jquery3.3.1 -->
  <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

  <!-- fancybox -->
  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js"></script>
  
<script src="/js/fancybox.js"></script>


  

  

  
<meta name="generator" content="Hexo 5.0.2"></head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/"><img src="/images/34339465.jpg" alt=""></a>
    <div class="nickname"><a href="/">Sditch</a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">主页</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">归档</a>
        </li>
      
        <li class="nav-item" data-path="/tags/">
          <a href="/tags/">标签</a>
        </li>
      
    </ul>
  </div>
</div>

<script src="/js/activeNav.js"></script>


      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->










<!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
<div class="container post-details" id="post-details">
  <div class="post-content">
    <div class="post-title">Non-local Neural Networks</div>
    <div class="post-attach">
      <span class="post-pubtime">2020-08-15</span>
      <span class="post-tags">
        
          <i class="iconfont icon-tags"></i>
          
          <span class="span--tag">
            <a href="/tags/cv/">
              #cv
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="markdown-body">
      <blockquote>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.07971.pdf">https://arxiv.org/pdf/1711.07971.pdf</a></p>
</blockquote>
<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>本文提出了non-local操作作为捕获远程依赖的构建块。non-local操作以所有位置特征的加权和来计算某个位置的响应。该模块可以插入许多计算机视觉体系结构中。在视频分类的任务上，我们的non-local模块在Kinetics和Charades数据集上可以竞争或优于当前的竞争获得者。在静态图像识别中，我们的非局部模型可改进目标检测/分割以及在COCO数据集上的姿态估计。</p>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>模型优点：</p>
<ul>
<li><blockquote>
<p>non-local operations capture long-range dependencies directly by computing interactions between any two positions, regardless of their positional distance</p>
</blockquote>
<p>non-local操作直接通过计算两个位置的相互影响捕获长距离依赖，而不管它的位置距离</p>
</li>
<li><blockquote>
<p>As we show in experiments, non-local operations are efficient and achieve their best results even with only a few layers </p>
</blockquote>
<p>non-local操作是高效的，只有几层的网络就能实现最好的结果</p>
</li>
<li><blockquote>
<p> our non-local operations maintain the variable input sizes and can be easily combined with other operations (e.g., convolutions as we will use).</p>
</blockquote>
<p>non-local操作保持了可变的输入大小，并且很轻松地应用到其他操作(如卷积)</p>
</li>
</ul>
<p>论文显示了non-local操作在视频分类任务中的有效性。在视频中，空间和时间的远距离像素之间会发生远程交互。在我们基本模块中，一个单个的non-local模块能够以前馈的方式捕获这些时空依赖。non-local神经网络（含有几个non-local模块）在视频分类任务中比2D/3D卷积更精确。除此之外，non-local的计算复杂度比三维卷积更低</p>
<h4 id="Non-local-神经网络"><a href="#Non-local-神经网络" class="headerlink" title="Non-local 神经网络"></a>Non-local 神经网络</h4><h5 id="1-公式"><a href="#1-公式" class="headerlink" title="1 公式"></a>1 公式</h5><img src="https://i.loli.net/2020/08/15/7Tlyj2tmR4nJodE.png" alt="image-20200815111637632" style="zoom:80%;" />

<p>i：计算响应的输出位置(空间/时间/时空)的索引；j：枚举所有位置的索引；</p>
<p>x：输入信号特征(图像、视频等)；y：输出信号特征；</p>
<p>f(x<del>i</del>, x<del>j</del>)：计算i到j的关系标量；g(x<del>j</del>)：计算位置j的输入信号的特征；</p>
<p>C(x)：结果经过C(x)归一化；</p>
<ul>
<li><p>公式(1)中可以看出：non-local就是考虑了所有位置j（卷积和recurrent操作是局部的）</p>
</li>
<li><p>non-local vs 全连接</p>
<ul>
<li><p>non-local基于不同位置的相关性计算(x<del>i</del> –&gt; x<del>j</del>)；fc基于学习的权重(x<del>i</del> –&gt; y<del>i</del>)</p>
</li>
<li><p>non-local可以加在卷积层/递归曾；fc加载末尾</p>
</li>
</ul>
</li>
</ul>
<h5 id="2-实例化"><a href="#2-实例化" class="headerlink" title="2 实例化"></a>2 实例化</h5><ul>
<li>为了简化，设W<del>g</del> 为学习的权重矩阵，g(x)为线性嵌入的形式：</li>
</ul>
<img src="http://latex.codecogs.com/svg.latex?g(x_j) = W_gx_j"/>

<ul>
<li><p>设高斯函数f如下，C(x)与嵌入式高斯函数一样：</p>
<img src="http://latex.codecogs.com/svg.latex?f(x_i, x_j) = e^{x_i^Tx_j}; \ x_i^Tx_j \ is \ dot-product \ similarity"/>
</li>
<li><p>嵌入式高斯函数：高斯函数的简单扩展是计算嵌入空间中的相似度，本文中如下</p>
<img src="https://i.loli.net/2020/08/15/CVzxJ1GlMLiBaDk.png" alt="image-20200815123858559" style="zoom:50%;" />

<p>自注意力模块是嵌入式高斯模型中的一种非局部操作的特例，我们由此得出：对于给定的i，1/C(X) f( x<del>i</del> , x<del>j</del> )是沿着维度j的softmax计算。因此自注意力机制的表示形式：</p>
<img src="http://latex.codecogs.com/svg.latex?y = softmax(x^T{W_\theta}^TW_{\phi}x)g(x)"/>

<p>本文工作将最近的self-attention模型与经典的非局部均值联系起来，将self-attention网络拓展到non-local网络，用于cv的图像/视频识别。尽管如此，由于softmax，作者也觉得attention对本文的研究不是必须的，具体见下文两点。</p>
</li>
<li><p>设f为一个点乘相似度, C(x)为归一化函数，N为x位置的数量：</p>
<img src="http://latex.codecogs.com/svg.latex?f(x_i, x_j) = {\theta}(x_i)^T{\phi}(x_j); \ \ C(x)=N;"/>

<p>这样设置归一化能简化梯度计算，以及可以保证可变大小的输入。在点乘相似度与嵌入式高斯模型的不同指出在于softmax的存在，它扮演了激励函数的角色</p>
</li>
<li><p>设f为一种拼接形式，[ . , . ]：拼接；w<del>f</del> ：权重向量——用于将拼接向量投影到标量；同样C(x) = N</p>
<img src="http://latex.codecogs.com/svg.latex?f(x_i, x_j) = ReLU(w_f^T[{\theta}(x_i), {\phi}(x_j)])"/>
</li>
<li><p>以上四种设定显示了non-local的灵活性。我们相信可替代的版本是可能的，并且可以改善结果</p>
</li>
</ul>
<h5 id="3-non-local模块"><a href="#3-non-local模块" class="headerlink" title="3 non-local模块"></a>3 non-local模块</h5><p>根据公式(1)，我们定义non-local模块：</p>
<img src="http://latex.codecogs.com/svg.latex?z_i = W_zy_i + x_i"/>

<img src="http://latex.codecogs.com/svg.latex?y_i=\frac{1}{C(x)}\sum_{\forall j}f(x_i,x_j)g(x_j)"/>

<p>“+x<del>i</del>“：残差连接；残差连接允许我们在任何预训练的模型中插入新的non-local块，而不会破坏它本来的形式；f函数的高斯和点乘算法都可以简单地通过矩阵乘法完成，而拼接算法则直接concat（如下图2）：</p>
<img src="https://i.loli.net/2020/08/15/PxI2jNQhdA81s4E.png" alt="image-20200815135931998" style="zoom:50%;" />

<p>提升模型的效率：</p>
<ul>
<li><p>如上图2，设置W<del>g</del>，W<del>θ</del>，W<del>φ</del> 的通道数为x中通道数的一半，权重矩阵W<del>z</del> 的通道与x保持一致(保证输出维度一致)</p>
</li>
<li><p>使用下采样的方法——将公式(1)的x通过池化等方法下采样一下，或在上图2中 φ/θ 后加一个最大池化层</p>
</li>
</ul>
<h3 id="视频分类模型"><a href="#视频分类模型" class="headerlink" title="视频分类模型"></a>视频分类模型</h3><h5 id="2D-ConvNet-baseline-C2D"><a href="#2D-ConvNet-baseline-C2D" class="headerlink" title="2D ConvNet baseline (C2D)"></a>2D ConvNet baseline (C2D)</h5><p>为了隔绝non-local网络与三维卷积网络的时间影响，我们构造了二维的基本结构，其时间维度得到简单处理（池化），如下表1，卷积核为二维，用于逐帧处理输入。模型直接初始化其权重经过ImageNet数据集预训练的ResNet权模型。 ResNet-101以相同的方式构建。</p>
<img src="https://i.loli.net/2020/08/15/8IwjJD4UGaYN7l6.png" alt="image-20200815144157292" style="zoom:60%;" />

<h5 id="Inflated-3D-ConvNet-I3D"><a href="#Inflated-3D-ConvNet-I3D" class="headerlink" title="Inflated 3D ConvNet (I3D)"></a>Inflated 3D ConvNet (I3D)</h5><p>通过增加卷积核的维度，表1中的C2D模型可转为3D卷积模型。比如(k, k)——&gt;(t, k, k)。其中，(t, k ,k)的卷积核的权重由(k, k)卷积核初始化，t平面的权重再重新缩放到1/t。如果视频由时间上重复的单个静态帧组成，则此初始化将产生与在静态帧上运行的2D预训练模型相同的结果。由于三维卷积的计算复杂性，我们只能每两个残差快扩展一个卷积核，扩展层数太多会让结果下降。conv<del>1</del> 卷积核扩展为(5, 7, 7)</p>
<h5 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h5><p>我们使用再ImageNet上预训练的模型，使用32帧输入短片微调模型。这些剪辑通过从原始全长视频中随机裁剪64个连续帧，然后每隔一帧丢掉所得。每帧图片大小为224×224——先将原视频像素（[256,320]）以短边缩放，然后随机裁剪所得。mini-batch=8，epoch=400k，lr=0.01(每150k个epoch乘以0.1)，momentum=0.9，weight decay=0.0001，全局池化后使用dropout(0.5)，启用BatchNorm微调模型。与微调ResNet不一样，我们将BN打开。</p>
<p>我们采用[20]中的方法来初始化在non-local模块中引入的权重层。仅增加一个BN层在最后的1×1×1层之后，BN层的参数初始化为0</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>训练过程曲线</li>
</ul>
<img src="https://i.loli.net/2020/08/15/YCrJmSHULBpIViz.png" alt="image-20200815152613031" style="zoom:60%;" />

<ul>
<li><p>non-local模块的实例——网络可学习到有意义的关系线索，而不管空间和时间上的距离</p>
<img src="https://i.loli.net/2020/08/15/An9wKvid4xJa3eH.png" alt="image-20200815152746747" style="zoom:70%;" />

</li>
</ul>
<img src="https://i.loli.net/2020/08/15/36PcNodyUpYFGxf.png" alt="image-20200815152849949" style="zoom:70%;" />

<ul>
<li><p>实验结果：C2D vs I3D</p>
<img src="https://i.loli.net/2020/08/15/hrd7NPq9sjxfGTv.png" alt="image-20200815153320905" style="zoom:80%;" />
</li>
<li><p>实验结果：I3D作者[7] vs Kinetics 2017获胜者[3] </p>
<p><img src="https://i.loli.net/2020/08/15/jNaMRhYgtpZJdbn.png" alt="image-20200815154707907"></p>
</li>
</ul>

    </div>
    
      <div class="prev-or-next">
        <div class="post-foot-next">
          
            <a href="/2020/08/14/A%C2%B2-Nets-Double-Attention-Networks/" target="_self">
              <i class="iconfont icon-chevronleft"></i>
              <span>PREV</span>
            </a>
          
        </div>
        <div class="post-attach">
          <span class="post-pubtime">2020-08-15</span>
          <span class="post-tags">
            
              <i class="iconfont icon-tags"></i>
              
              <span class="span--tag">
                <a href="/tags/cv/">
                  #cv
                </a>
              </span>
              
            
          </span>
        </div>
        <div class="post-foot-prev">
          
        </div>
      </div>
    
  </div>
  
  <div class="post-catalog" id="catalog">
    <div class="title">目录</div>
    <div class="catalog-content">
      <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Non-local-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">Non-local 神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%85%AC%E5%BC%8F"><span class="toc-text">1 公式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%AE%9E%E4%BE%8B%E5%8C%96"><span class="toc-text">2 实例化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-non-local%E6%A8%A1%E5%9D%97"><span class="toc-text">3 non-local模块</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-text">视频分类模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2D-ConvNet-baseline-C2D"><span class="toc-text">2D ConvNet baseline (C2D)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Inflated-3D-ConvNet-I3D"><span class="toc-text">Inflated 3D ConvNet (I3D)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-text">训练</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-text">实验结果</span></a>
    </div>
  </div>

  <script src="/js/catalog.js"></script>



  
    <div class="comments-container">
      





    </div>
  
</div>


        <div class="footer">
  <div class="social">
    <ul>
      
        <li>
          <a title="github" href="https://github.com/Sditch/sditch.github.io">
            <i class="iconfont icon-github"></i>
          </a>
        </li>
      
        <li>
          <a title="rss" href="atom.xml">
            <i class="iconfont icon-rss"></i>
          </a>
        </li>
      
    </ul>
  </div>
  
    <div class="footer-more">
      <a href="https://github.com/Sditch/sditch.github.io">Copyright © Switch 2020</a>
    </div>
  
</div>

      </div>

      <div class="back-to-top hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>

<script src="/js/backtotop.js"></script>


    </div>
  </body>
</html>
